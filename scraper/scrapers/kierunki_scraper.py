"""
ModuÅ‚ do pobierania informacji o kierunkach studiÃ³w z planu UZ.
"""
import requests
from bs4 import BeautifulSoup
from typing import List

from scraper.models import Kierunek

BASE_URL = "https://plan.uz.zgora.pl/"


def fetch_page(url: str) -> str:
    """Pobiera zawartoÅ›Ä‡ strony HTML."""
    try:
        response = requests.get(url)
        response.raise_for_status()
        return response.text
    except requests.exceptions.RequestException as e:
        print(f"âŒ BÅ‚Ä…d pobierania strony: {e}")
        return ""


def parse_departments_and_courses(html: str) -> List[Kierunek]:
    """
    Parsuje HTML i wyodrÄ™bnia wydziaÅ‚y oraz kierunki.
    """
    soup = BeautifulSoup(html, "html.parser")
    wynik = []

    main_container = soup.find("div", class_="container main")
    if not main_container:
        print("âŒ Nie znaleziono gÅ‚Ã³wnego kontenera.")
        return wynik

    wydzialy_items = main_container.find_all("li", class_="list-group-item")
    wydzial = None

    for item in wydzialy_items:
        item_text = item.get_text(strip=True)

        # JeÅ›li to nagÅ‚Ã³wek wydziaÅ‚u
        if ("WydziaÅ‚" in item_text or "SzkoÅ‚y" in item_text) and not item.find("a", recursive=False):
            # Pobierz tylko pierwszy wÄ™zeÅ‚ tekstowy, bez zagnieÅ¼dÅ¼onych elementÃ³w
            text_nodes = [n for n in item.contents if isinstance(n, str)]
            if text_nodes:
                wydzial = text_nodes[0].strip()
            else:
                wydzial = item_text.split()[0]

            print(f"\nğŸ” WydziaÅ‚: {wydzial}\n")

        # JeÅ›li to kierunek i mamy aktywny wydziaÅ‚
        elif item.find("a") and wydzial:
            a_tag = item.find("a")
            nazwa_kierunku = a_tag.get_text(strip=True)
            link = BASE_URL + a_tag["href"]

            # PomiÅ„ studia podyplomowe
            if "Studia podyplomowe" not in nazwa_kierunku:
                # Wydobycie ID kierunku z linku
                kierunek_id = None
                if "ID=" in link:
                    try:
                        kierunek_id = link.split("ID=")[1].split("&")[0]
                    except (IndexError, ValueError):
                        kierunek_id = None

                if kierunek_id:
                    kierunek = Kierunek(
                        kierunek_id=kierunek_id,
                        nazwa=nazwa_kierunku,
                        wydzial=wydzial,
                        link=link
                    )
                    wynik.append(kierunek)
                    print(f"ğŸ“Œ Dodano kierunek: {nazwa_kierunku}")

    return wynik


def scrape_kierunki() -> List[Kierunek]:
    """Scrapuje kierunki i wydziaÅ‚y."""
    url = BASE_URL + "grupy_lista_kierunkow.php"
    print(f"ğŸ” Pobieram dane z: {url}")
    html = fetch_page(url)

    if not html:
        print("âŒ Nie udaÅ‚o siÄ™ pobraÄ‡ strony.")
        return []

    return parse_departments_and_courses(html)


if __name__ == "__main__":
    kierunki = scrape_kierunki()
    print(f"\nPobrano {len(kierunki)} kierunkÃ³w.")